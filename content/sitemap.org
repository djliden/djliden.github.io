* [[file:about.org][(2022-09-20) About Me]]
My name is Dan. I am a data scientist at bit.io, which offers the fastest way to
get a cloud PostgreSQL database. In my role, I use bit.io databases to manage
the data in various data science research projects. I've analyzed data and
written about topics such as [[https://innerjoin.bit.io/the-high-climate-cost-of-meat-oil-and-landfills-b7c674d1dd68][methane emissions]], [[https://innerjoin.bit.io/ask-a-bayesian-who-is-better-at-wordle-76a0e5199ed][Bayesian statistics]], [[https://innerjoin.bit.io/resignations-have-increased-every-year-since-2010-2b88b53c7f32][labor
turnover]], [[https://medium.com/the-inner-join/a-case-for-doubling-the-size-of-the-us-house-of-representatives-2799a5268920][the size of the House of Representatives]], and much more.

Prior to starting at bit.io, I was the Director of Data Analytics at the Guinn
Center for Policy Priorities in Las Vegas, Nevada. In this role, I was
responsible for conducting data-driven policy analysis and for supporting
ongoing research and data analysis at the Guinn Center. Most of my work a the
Guinn Center focused on public health, climate change, and the 2020 Census.
* [[file:index.org][(2022-06-04) Daniel Liden's Home Page]]
(No preview)
* [[file:archive.org][(2021-12-02) Posts Archive]]
(No preview)
* posts
** [[file:posts/20220918-jq-example.org][(2022-09-18) Processing a JSON API Response with jq]]
There are countless ways of processing JSON data and converting it to different
formats. Historically, I've used Python and loaded the data into a Pandas
Dataframe for processing. This isn't really necessary for simple tasks,
though. Sometimes, a lightweight command line tool does the job just fine. Enter
~jq~. [[https://stedolan.github.io/jq/][jq]] is "like ~sed~ for JSON data." This post walks through an example of
downloading data from an API, extracting a few fields based on some conditions,
and converting the results to a CSV using ~jq~.
** [[file:posts/20220724-html5.org][(2022-07-24) Figures and Captions Don't Appear as Expected with Default Export Options]]
I noticed that some of the formatting on this site was a little off and some of
the org-mode components weren't being translated to HTML in quite the way I
expected. Fixing this was simple, but /finding/ the solution wasn't. In short, it
was necessary to set the ~org-html-doctype~ to ~html5~ (the default is
~xhtml-strict~). Furthermore, I set ~org-html-html5-fancy~ to ~t~. These ensure the
org export process takes advantage of block elements offered in the ~html5~
standard.
** [[file:posts/20220719-julia-plots.org][(2022-07-19) Basic Plotting in Julia]]
In this short post, I show one of the many ways of using Julia within emacs
org mode, and will describe some of the basic plotting functionality in Julia.
** [[file:posts/20220208-org-source.org][(2022-02-08) Org Mode Headlines in Org Source Blocks]]
When writing about org mode, one often wants to show what particular org
headline look like in terms of formatting, properties, tags, options,
etc,. However, even within a babel org source block, an org header will be
parsed and exported as a header. We can get around this by prepending the
headline with a comma. The comma won't show up when exported: all that is
exported is a nicely-formatted example of an org headline.
** [[file:posts/20220116-org-time.org][(2022-01-29) Task Repeaters in Org Mode]]
I recently started using org-mode to keep track of a few habits (morning
meditation, getting some sunlight and exercise before my morning coffee, etc.)
and needed to make use of org-mode's calendar features to do so. I've previously
set deadlines and scheduled dates for my ~TODO~ entries, but have seldom used
repeat intervals. My early attempts ( ~date +1d~) worked fine but required some
extra steps if I ever missed a day. This post discusses the ~.+~ and ~++~
-style repeat intervals, which allow more control over what happens when you
complete a task after the scheduled date.
** [[file:posts/20211209-R-babel.org][(2021-12-11) Org Babel Source Blocks for R]]
[[https://orgmode.org/worg/org-contrib/babel/intro.html][Org Babel]] is one of the best tools available for [[https://www-cs-faculty.stanford.edu/~knuth/lp.html][literate programming]]. As a data scientist, I use it
as a plain-text alternative to Jupyter notebooks. Org-mode files are much easier to track with
version control and don't require the overhead of a browser. There are tradeoffs: Jupyter notebooks
handle the display of different types of output (text results, images, interactive figures, etc.) in
a way that is both seamless and visually appealing. Displaying figures at all can be a challenge
when getting started with org-babel. This post covers the basics of using org-babel for common data
science tasks in R.
** [[file:posts/20211203-this-site.org][(2021-12-03) Made with Org-Mode]]
I finally made a personal site using org-mode's built-in ~ox-publish~ exporter.

I've written my personal website with org-mode for years (it is, after all, [[https://karl-voit.at/2017/09/23/orgmode-as-markup-only/][one of the most
reasonable markup languages to use for text]]). But until this point, I've used Hugo (with the ~ox-Hugo~
exporter). It worked fine, but it always seemed /just a little bit too complicated/ for my needs. I
wanted to find something where I could basically understand all of the components and where the gap
between my org-mode files and the published output was as small as possible. I wanted to focus more
on the writing and less on understanding the framework.
** [[file:posts/20211201-resources.org][(2021-12-02) Resources]]
Here are some resources to reference for building a simple site with org-mode. I've extensively
used the sites listed as models for building the present site and expect to continue to reference
them for some time.
** drafts
*** [[file:posts/drafts/20220611-vertex.org][(2022-06-11) Getting Started with Vertex AI Custom Model Training]]
I have long wanted an easy solution to training a small version of a deep learning
model on my laptop and then training a larger version in the cloud with as
little extra code as possible. In an ideal world, this would mean passing a
~--cloud~ argument to the training utility.

This post describes an approach that, while not perfect, does begin to solve the
problem of simple scaling from local prototyping on a laptop to training a much
larger model in the cloud. It uses Google's [[https://cloud.google.com/vertex-ai/docs/training/custom-training][[Vertex AI Custom Training]â€‹]] API
(via the Python SDK). The existing documentation on this use case for Vertex AI
is not very good. I hope this guide will provide a straightforward approach to a
local prototyping/cloud scaling approach to model training that will be
accessible to those without a lot of experience in cloud ML Ops.