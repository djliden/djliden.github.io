* [[file:index.org][(2022-06-04) Daniel Liden's Home Page]]
(No preview)
* [[file:about.org][(2021-12-03) About Me]]
My name is Dan. I'm a data scientist at [[https://bit.io][bit.io]], where we offer the fastest and easiest way to get a
secure, private PostgreSQL database. In this role, I write and I work on internal analytics.

Prior to starting at bit.io, I was the Director of Data Analytics at the Guinn Center for Policy Priorities in Las Vegas, Nevada. In this role, I was responsible for conducting data-driven policy analysis and for supporting ongoing research and data analysis at the Guinn Center.
* [[file:archive.org][(2021-12-02) Posts Archive]]
(No preview)
* posts
** [[file:posts/20220719-julia-plots.org][(2022-07-19) Basic Plotting in Julia]]
In this short post, I show one of the many ways of using Julia within emacs
org mode, and will describe some of the basic plotting functionality in Julia.
** [[file:posts/20220208-org-source.org][(2022-02-08) Org Mode Headlines in Org Source Blocks]]
When writing about org mode, one often wants to show what particular org
headline look like in terms of formatting, properties, tags, options,
etc,. However, even within a babel org source block, an org header will be
parsed and exported as a header. We can get around this by prepending the
headline with a comma. The comma won't show up when exported: all that is
exported is a nicely-formatted example of an org headline.
** [[file:posts/20220116-org-time.org][(2022-01-29) Task Repeaters in Org Mode]]
I recently started using org-mode to keep track of a few habits (morning
meditation, getting some sunlight and exercise before my morning coffee, etc.)
and needed to make use of org-mode's calendar features to do so. I've previously
set deadlines and scheduled dates for my ~TODO~ entries, but have seldom used
repeat intervals. My early attempts ( ~date +1d~) worked fine but required some
extra steps if I ever missed a day. This post discusses the ~.+~ and ~++~
-style repeat intervals, which allow more control over what happens when you
complete a task after the scheduled date.
** [[file:posts/20211209-R-babel.org][(2021-12-11) Org Babel Source Blocks for R]]
[[https://orgmode.org/worg/org-contrib/babel/intro.html][Org Babel]] is one of the best tools available for [[https://www-cs-faculty.stanford.edu/~knuth/lp.html][literate programming]]. As a data scientist, I use it
as a plain-text alternative to Jupyter notebooks. Org-mode files are much easier to track with
version control and don't require the overhead of a browser. There are tradeoffs: Jupyter notebooks
handle the display of different types of output (text results, images, interactive figures, etc.) in
a way that is both seamless and visually appealing. Displaying figures at all can be a challenge
when getting started with org-babel. This post covers the basics of using org-babel for common data
science tasks in R.
** [[file:posts/20211203-this-site.org][(2021-12-03) Made with Org-Mode]]
I finally made a personal site using org-mode's built-in ~ox-publish~ exporter.

I've written my personal website with org-mode for years (it is, after all, [[https://karl-voit.at/2017/09/23/orgmode-as-markup-only/][one of the most
reasonable markup languages to use for text]]). But until this point, I've used Hugo (with the ~ox-Hugo~
exporter). It worked fine, but it always seemed /just a little bit too complicated/ for my needs. I
wanted to find something where I could basically understand all of the components and where the gap
between my org-mode files and the published output was as small as possible. I wanted to focus more
on the writing and less on understanding the framework.
** [[file:posts/20211201-resources.org][(2021-12-02) Resources]]
Here are some resources to reference for building a simple site with org-mode. I've extensively
used the sites listed as models for building the present site and expect to continue to reference
them for some time.
** drafts
*** [[file:posts/drafts/20220611-vertex.org][(2022-06-11) Getting Started with Vertex AI Custom Model Training]]
I have long wanted an easy solution to training a small version of a deep learning
model on my laptop and then training a larger version in the cloud with as
little extra code as possible. In an ideal world, this would mean passing a
~--cloud~ argument to the training utility.

This post describes an approach that, while not perfect, does begin to solve the
problem of simple scaling from local prototyping on a laptop to training a much
larger model in the cloud. It uses Google's [[https://cloud.google.com/vertex-ai/docs/training/custom-training][[Vertex AI Custom Training]â€‹]] API
(via the Python SDK). The existing documentation on this use case for Vertex AI
is not very good. I hope this guide will provide a straightforward approach to a
local prototyping/cloud scaling approach to model training that will be
accessible to those without a lot of experience in cloud ML Ops.